{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Search Spaces with Hyperopt\n",
    "\n",
    "In this notebooks, we will create a conditional (or nested) hyperparameter space to optimize the hyperparameters of 3 different off-the-shelf algorithms.\n",
    "\n",
    "Utilizing the breast cancer dataset, we will optimize the hyperparameters for a linear regression, a random forest and a gradient boosting machine within the same search.\n",
    "\n",
    "By the end of the search, we will know:\n",
    "\n",
    "- which algorithm returns the best results\n",
    "- which are the best hyperparameters for said algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp: define the hyperparameter space\n",
    "# fmin: optimization function\n",
    "# Trials: to evaluate the different searched hyperparameters\n",
    "from hyperopt import hp, fmin, Trials\n",
    "\n",
    "# the search algorithms\n",
    "from hyperopt import anneal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8   \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9   ...     20     21      22      23      24      25      26      27  \\\n",
       "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       28       29  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "breast_cancer_X, breast_cancer_y = load_breast_cancer(return_X_y=True)\n",
    "X = pd.DataFrame(breast_cancer_X)\n",
    "y = pd.Series(breast_cancer_y).map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.627417\n",
       "1    0.372583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target:\n",
    "# percentage of benign (0) and malign tumors (1)\n",
    "\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Hyperparameter Space\n",
    "\n",
    "- [Hyperopt search space](http://hyperopt.github.io/hyperopt/getting-started/search_spaces/)\n",
    "\n",
    "We need to define 3 spaces, 1 for each algorithm, nested or conditional to the algorithm. We create all this spaces in a master configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# determine the hyperparameter space\n",
    "# ==================================\n",
    "\n",
    "# we create dictionaries with 2 keys: \"model\" and \"params\"\n",
    "# in \"model\" we specify the algorithm, in \"params\", we pass\n",
    "# a dictionary with the space for that particular algorithm\n",
    "\n",
    "# important: pass the model as class and not\n",
    "# instantiated, thus LogisticRegression istead of\n",
    "# LogisticRegression()\n",
    "\n",
    "# within the params dictionaries, the keys should be\n",
    "# the parameter names of the algos, as per their \n",
    "# documentation\n",
    "\n",
    "# within the hp in each dictionary, give different names to\n",
    "# later on identify to which model was the hyperparameter assigned\n",
    "# see for example n_estimators_rf and n_estimators_gbm later\n",
    "\n",
    "\n",
    "# the nested space\n",
    "param_grid = hp.choice('classifier', [\n",
    "    \n",
    "    # algo 1\n",
    "    {'model': LogisticRegression,\n",
    "    'params': {\n",
    "        'penalty': hp.choice('penalty', ['l1','l2']),\n",
    "        'C' : hp.uniform('C', 0.001, 10),\n",
    "        'solver': 'saga', # the only solver that works with both penalties\n",
    "    }},\n",
    "    \n",
    "    # algo 2\n",
    "    {'model': RandomForestClassifier,\n",
    "    'params': {\n",
    "        'n_estimators': hp.quniform('n_estimators_rf', 50, 1500, 50),\n",
    "        'max_depth': hp.quniform('max_depth_rf', 1, 5, 1),\n",
    "        'criterion': hp.choice('criterion_rf', ['gini', 'entropy']),\n",
    "    }},\n",
    "    \n",
    "    # algo 3\n",
    "    {'model': GradientBoostingClassifier,\n",
    "    'params': {\n",
    "        'n_estimators': hp.quniform('n_estimators_gbm', 50, 1500, 50),\n",
    "        'max_depth': hp.quniform('max_depth_gbm', 1, 5, 1),\n",
    "        'criterion': hp.choice('criterion_gbm', ['friedman_mse', 'mse']),\n",
    "    }},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the objective function\n",
    "\n",
    "This is the hyperparameter response space, the function we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \n",
    "    # instantiate the model\n",
    "    model = params['model']() # don't forget the () to instantiate the class\n",
    "    \n",
    "    # capture the sampled hyperparameters\n",
    "    hyperparams = params['params']\n",
    "        \n",
    "    try:        \n",
    "        # for tree based algorithms\n",
    "        hyperparams['n_estimators'] = int(hyperparams['n_estimators'])\n",
    "        hyperparams['max_depth'] = int(hyperparams['max_depth'])\n",
    "    except:\n",
    "        pass        \n",
    "        \n",
    "    # in case you want to visualize what is being sampled:\n",
    "    print(model, hyperparams)\n",
    "\n",
    "    # pass the parameters to the model\n",
    "    model.set_params(**hyperparams)\n",
    "\n",
    "    # train with cv\n",
    "    cross_val_data = cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "\n",
    "    # to minimize, we negate the score\n",
    "    loss = -cross_val_data.mean()\n",
    "    print(loss)\n",
    "    print()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()                              \n",
      "{'criterion': 'entropy', 'max_depth': 1, 'n_estimators': 1250}\n",
      "-0.9171413381939697                                   \n",
      "RandomForestClassifier()                                                         \n",
      "{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 250}                       \n",
      "-0.9522670312143996                                                              \n",
      "RandomForestClassifier()                                                         \n",
      "{'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 750}                    \n",
      "-0.9397167160325055                                                              \n",
      "LogisticRegression()                                                             \n",
      "{'C': 2.6874248381351316, 'penalty': 'l1', 'solver': 'saga'}                     \n",
      "-0.9120148856990963                                                              \n",
      "RandomForestClassifier()                                                         \n",
      "{'criterion': 'gini', 'max_depth': 3, 'n_estimators': 400}                       \n",
      "  8%|▊         | 4/50 [00:03<00:40,  1.14trial/s, best loss: -0.9522670312143996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9397357028935976                                                              \n",
      "RandomForestClassifier()                                                         \n",
      "{'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 600}                    \n",
      "-0.942241968557758                                                               \n",
      "RandomForestClassifier()                                                         \n",
      "{'criterion': 'gini', 'max_depth': 4, 'n_estimators': 1000}                      \n",
      "-0.942241968557758                                                               \n",
      "LogisticRegression()                                                             \n",
      "{'C': 3.3166349629202334, 'penalty': 'l1', 'solver': 'saga'}                     \n",
      "-0.9120148856990963                                                              \n",
      "RandomForestClassifier()                                                         \n",
      "{'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 650}                    \n",
      " 16%|█▌        | 8/50 [00:05<00:28,  1.45trial/s, best loss: -0.9522670312143996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9347041847041847                                                              \n",
      "GradientBoostingClassifier()                                                     \n",
      "{'criterion': 'mse', 'max_depth': 3, 'n_estimators': 550}                        \n",
      "-0.9497797524113313                                                              \n",
      "RandomForestClassifier()                                                          \n",
      "{'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 900}                     \n",
      "-0.9397357028935976                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'friedman_mse', 'max_depth': 4, 'n_estimators': 450}                \n",
      "-0.9422989291410344                                                               \n",
      "RandomForestClassifier()                                                          \n",
      "{'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 150}                     \n",
      "-0.9397546897546899                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 1, 'n_estimators': 300}                         \n",
      "-0.9647983595352017                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 3, 'n_estimators': 750}                         \n",
      "-0.9497797524113313                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'friedman_mse', 'max_depth': 1, 'n_estimators': 400}                \n",
      "-0.9622920938710413                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 1, 'n_estimators': 800}                         \n",
      "-0.9723551302498671                                                               \n",
      "RandomForestClassifier()                                                          \n",
      "{'criterion': 'gini', 'max_depth': 4, 'n_estimators': 550}                        \n",
      "-0.9447482342219184                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 3, 'n_estimators': 800}                         \n",
      "-0.9497797524113313                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 1, 'n_estimators': 1000}                        \n",
      "-0.9698298777246146                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 550}                         \n",
      "-0.9547922837396522                                                               \n",
      "LogisticRegression()                                                              \n",
      "{'C': 7.239147733028732, 'penalty': 'l1', 'solver': 'saga'}                       \n",
      "-0.9120148856990963                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'friedman_mse', 'max_depth': 2, 'n_estimators': 950}                \n",
      " 44%|████▍     | 22/50 [00:14<00:21,  1.28trial/s, best loss: -0.9723551302498671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.959823801929065                                                                \n",
      "LogisticRegression()                                                              \n",
      "{'C': 6.052414940734376, 'penalty': 'l1', 'solver': 'saga'}                       \n",
      "-0.9120148856990963                                                               \n",
      "LogisticRegression()                                                              \n",
      "{'C': 4.318048419965579, 'penalty': 'l2', 'solver': 'saga'}                       \n",
      "-0.9120148856990963                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'friedman_mse', 'max_depth': 3, 'n_estimators': 950}                \n",
      " 50%|█████     | 25/50 [00:15<00:17,  1.45trial/s, best loss: -0.9723551302498671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9523050049365839                                                               \n",
      "RandomForestClassifier()                                                          \n",
      "{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 500}                        \n",
      "-0.9522670312143996                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 1, 'n_estimators': 450}                         \n",
      "-0.9648173463962938                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 1100}                        \n",
      "-0.9573175362649047                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 850}                         \n",
      "-0.959823801929065                                                                \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 3, 'n_estimators': 800}                         \n",
      "-0.9447292473608263                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 1, 'n_estimators': 450}                         \n",
      "-0.9648173463962938                                                               \n",
      "LogisticRegression()                                                              \n",
      "{'C': 6.058636003485811, 'penalty': 'l1', 'solver': 'saga'}                       \n",
      "-0.9120148856990963                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 1, 'n_estimators': 800}                         \n",
      " 66%|██████▌   | 33/50 [00:22<00:13,  1.23trial/s, best loss: -0.9723551302498671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9723551302498671                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 1, 'n_estimators': 700}                         \n",
      "-0.9698488645857067                                                               \n",
      "LogisticRegression()                                                              \n",
      "{'C': 3.934740001885701, 'penalty': 'l2', 'solver': 'saga'}                       \n",
      "-0.9120148856990963                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 950}                         \n",
      " 72%|███████▏  | 36/50 [00:23<00:08,  1.70trial/s, best loss: -0.9723551302498671]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/kuhn/Github_local/hyperparameter-optimization/.venv/hyperparameter-optimization/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.959823801929065                                                                \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'friedman_mse', 'max_depth': 1, 'n_estimators': 900}                \n",
      "-0.9723551302498671                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 1100}                        \n",
      "-0.9598427887901572                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 1, 'n_estimators': 800}                         \n",
      "-0.9723551302498671                                                               \n",
      "RandomForestClassifier()                                                          \n",
      "{'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 100}                     \n",
      "-0.9522860180754918                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'friedman_mse', 'max_depth': 1, 'n_estimators': 500}                \n",
      "-0.9673236120604543                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 950}                         \n",
      "-0.959823801929065                                                                \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'friedman_mse', 'max_depth': 1, 'n_estimators': 850}                \n",
      "-0.9723551302498671                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'friedman_mse', 'max_depth': 2, 'n_estimators': 600}                \n",
      "-0.9547922837396522                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 2, 'n_estimators': 850}                         \n",
      "-0.959823801929065                                                                \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 1, 'n_estimators': 850}                         \n",
      "-0.9723551302498671                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'friedman_mse', 'max_depth': 2, 'n_estimators': 800}                \n",
      "-0.959823801929065                                                                \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 1, 'n_estimators': 800}                         \n",
      "-0.9723551302498671                                                               \n",
      "GradientBoostingClassifier()                                                      \n",
      "{'criterion': 'mse', 'max_depth': 1, 'n_estimators': 650}                         \n",
      "-0.9698488645857067                                                               \n",
      "100%|██████████| 50/50 [00:34<00:00,  1.45trial/s, best loss: -0.9723551302498671]\n"
     ]
    }
   ],
   "source": [
    "# fmin performs the minimization\n",
    "# anneal.suggest samples the parameters\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "anneal_search = fmin(\n",
    "    fn=objective,\n",
    "    space=param_grid,\n",
    "    max_evals=50,\n",
    "    rstate=np.random.RandomState(42),\n",
    "    algo=anneal.suggest,  # annealing search\n",
    "    trials=trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 2,\n",
       " 'criterion_gbm': 1,\n",
       " 'max_depth_gbm': 1.0,\n",
       " 'n_estimators_gbm': 800.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anneal_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 2,\n",
       " 'criterion_gbm': 1,\n",
       " 'max_depth_gbm': 1.0,\n",
       " 'n_estimators_gbm': 800.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9723551302498671"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.average_best_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 16,\n",
       " 'spec': None,\n",
       " 'result': {'loss': -0.9723551302498671, 'status': 'ok'},\n",
       " 'misc': {'tid': 16,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'C': [],\n",
       "   'classifier': [16],\n",
       "   'criterion_gbm': [16],\n",
       "   'criterion_rf': [],\n",
       "   'max_depth_gbm': [16],\n",
       "   'max_depth_rf': [],\n",
       "   'n_estimators_gbm': [16],\n",
       "   'n_estimators_rf': [],\n",
       "   'penalty': []},\n",
       "  'vals': {'C': [],\n",
       "   'classifier': [2],\n",
       "   'criterion_gbm': [1],\n",
       "   'criterion_rf': [],\n",
       "   'max_depth_gbm': [1.0],\n",
       "   'max_depth_rf': [],\n",
       "   'n_estimators_gbm': [800.0],\n",
       "   'n_estimators_rf': [],\n",
       "   'penalty': []}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': datetime.datetime(2022, 10, 7, 13, 45, 22, 377000),\n",
       " 'refresh_time': datetime.datetime(2022, 10, 7, 13, 45, 22, 957000)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convergence\n",
    "\n",
    "pd.Series(trials.losses()).sort_values(ascending=False).reset_index(drop=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('hyperparameter-optimization': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "257px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "2b5166dc44e1c447f633fd495edf8ade93e6e9a81bfb1e7ede5f55ce3b3ba8fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
